<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Credit Card Fraud Detection</title>
</head>
<body>

<h1>Credit Card Fraud Detection</h1>

<h2>1. Introduction / Background</h2>
<p>
    Credit card fraud is a significant issue in the financial sector, leading to substantial financial losses. Fraudulent activities, such as card cloning, identity theft, and unauthorized transactions are common challenges for credit card companies. To combat this, many institutions use machine learning to detect unusual transaction patterns and flag potential fraud.
</p>

<h3>Past Cases / Literature Review</h3>
<ul>
    <li><strong>Maniraj et al.</strong>: At SRM Institute, assistant professor S.P. Maniraj built a very similar model to what we are aiming to do. His team’s model was able to successfully identify new transactions as fraudulent or not with an accuracy of 99.7% [1].</li>
    <li><strong>Safa and Ganga</strong>: They created a model that heavily utilized logistic regression to analyze distorted credit card data. The logistic regression method had a 99.07% accuracy [2].</li>
</ul>

<h3>Dataset Description</h3>
<p>
    We plan to use publicly available datasets like the Kaggle Credit Card Fraud Detection Dataset, which contains real credit card transactions with fraudulent transactions. This dataset contains transactions in the year 2023 by European cardholders. This data is spanned over the whole year, where there are over 550,000 records [3].
</p>
<p><strong>Dataset Link:</strong> <a href="https://www.kaggle.com/datasets/nelgiriyewithana/credit-card-fraud-detection-dataset-2023">Kaggle Credit Card Fraud Dataset</a></p>

<h2>2. Problem Definition</h2>

<h3>Problem</h3>
<p>
    The challenge is to detect fraudulent transactions using both supervised methods (classification) and unsupervised methods (anomaly detection) to identify patterns that indicate fraud.
</p>

<h3>Motivation</h3>
<p>
    The motivation behind creating a machine learning model to detect credit card fraud stems from the desire to protect consumers and financial institutions from significant financial losses. As online transactions and digital payments increase, so does the risk of fraud. This offers a more adaptive approach, learning from patterns in transactional data to detect suspicious activity in real-time, reducing false positives, and enhancing security without compromising user experience.
</p>

<h2>3. Methods</h2>

<h3>Preprocessing Method</h3>
<ul>
    <li>Drop Unnecessary Columns: We decided to remove the id column as it is an identifier and does not contribute to predictive modeling</li>
    <li>Handling Missing Values: We checked for missing values and removed any rows containing them to ensure data integrity </li>
    <li>Feature Scaling: Although feature v1-v28 are already anonymized and likely normalized, the Amount column was scaled using Standard Scaler to bring it in line with the other features.</li>
    <li>Class Imbalance: We applied SMOTE to balance the dataset because fraud transactions are much more rare than non fraud ones. Balancing the classes ensures the supervised learning models can better detect fraud without being biased toward the majority class.</li>
<p><strong>Data Split:</strong> We split the preprocessed data into training(80%) and validation(20%) sets. This split provides a strong basis for evaluating model performance during supervised learning</p>
    <li>SMOTE:</li>
    <ul>
        <li>Handles imbalance in datasets, especially in binary classification tasks like fraud detection and transactions where they are much more rare</li>
        <li>ML models tend to be more biased towards the majority class, which results in a poor performance. In this situation, the model might classify most transactions are non fraudulent, leading to high accuracy but low effectiveness in detection.</li>
    </ul>
</ul>
<h3>Machine Learning Models</h3>
<ul>
    <li>We decided to implement a logistic regression model for classification. Logistic regression was chosen because it's a model well-suited for binary classification tasks. In this case, the model is being trained to distinguish between two classes, fraudulent and non-fraudulent.</li>
    <li>Why we chose logistic regression:</li>
    <ul>
        <li><strong>Binary Classification:</strong> Logistic regression is ideal for problems where the output variable is binary, as it can predict probabilities for each class.</li>
        <li><strong>Interpretable Results:</strong> This model allows for easy interpretation of feature importance, which is valuable for understanding patterns in fraud detection.</li>
        <li><strong>Efficiency and Speed:</strong> It performs well with a moderate number of features without excessive computation, making it a good initial choice for data exploration.</li>
    </ul>
</ul>

<h2>4. Results and Discussion</h2>
<h3>Visualizations</h3>
<ul>
    <li>Preprocessing Code Implementation</li>
    <ul>
        <img src="preprocessing.png">
    </ul>
    <li>Feature Correlation Map</li>
    <ul>
        <img src="featurecorrelationmap.png" height="700" width="800">
    </ul>
    <li>Correlation Box Plots</li>
    <ul>
        <img src="v3.png"width="800">
        <img src="v4.png"width="800">
    </ul>
    <li>Logistic Regression Learning Curve</li>
    <ul>
        <img src="logisticregression.png" height="700" width="800">
    </ul>
    <li>ROC Curve</li>
    <ul>
        <img src="roccurve.png" height="700" width="800">
    </ul>
</ul>

<h3>Quantitative Metrics</h3>
<ul>
    <li>The training accuracy score was 96%.</li>
    <li>The cross-validation accuracy was 96.49%.</li>
</ul>

<h3>Analysis of Algorithm/Model</h3>
<ul>
    <li>The Logistic regression model achieved a high accuracy score (96%), with cross-validation reporting an average score of approximately 96.49%. This high accuracy indicates that the model can effectively distinguish between the two classes in the dataset, suggesting that the selected features capture useful patterns for classification. It is essential to ensure the model’s performance is robust by examining the learning curve. The learning curve shows consistent performance between the training and validation scores, suggesting no major overfitting or underfitting issues, although the gap between them should be carefully monitored if the model is further optimized.</li>
</ul>

<h3>Analysis</h3>
<ul>
    <li><strong>Correlation box plots</strong></li>
    <ul>
        <li>The box plots provide valuable insights into the relationship between certain anonymized features and the Class Label</li>
        <ul>
            <li>V3,V10,V12,V14 (Negative Correlation with Class):</li>
            <ul>
                <li>A negative correlation indicates that as the feature values increase, the likelihood of the transaction being fraudulent decreases</li>
                <li>Fraud transactions for these features tend to have a lower median value for these features compared to the other</li>
                <li>There is a lower median and lower spread</li>
            </ul>
            <li>V4, V11:</li>
            <ul>
                <li>Positive correlation means that as the feature values increase, the likelihood of the transaction being fraudulent increases</li>
                <li>For both V4 and 11, the median values of fraudulent transactions are higher than non fraud transactions</li>
                <li>Higher values of V4 and 11 are more common in fraudulent transactions, which could serve as a signal for the model when detecting fraud.</li>
            </ul>
            <li>V10 has a consistent lower value for fraud cases than non fraud. V10 could be an indicator that a transaction is potentially fraudulent when it is below a threshold.</li>
        </ul>
        <li><strong>Takeaways</strong></li>
        <ul>
            <li>Patterns: These plots show that certain features have distinct distributions based on the class of either fraud or not. Some features tend to show a lower value in fraud cases while others trend higher in cases of fraud</li>
            <li>These features might be important for the model, as they show differences between fraudulent and non fraudulent transaction</li>
            <li>The presence of outliers, especially in non fraud transactions, is expected in real world data, as non fraud will have more variability</li>
        </ul>
    </ul>
    <li><strong>Learning Curve</strong></li>
    <ul>
        <li>The learning curve shown provides details about the performance of the logistic regression model when the training size increases.</li>
        <li><strong>Training vs Cross Validation</strong></li>
        <ul>
            <li><strong>Training Score(Orange Line):</strong> Model's performance on training data</li>
            <li><strong>Cross Validation Score(Blue Line):</strong> Model's performance on unseen validation data</li>
            <li>Since the lines are very close to each other, it appears that the model is able to generalize well and does not appear to significantly under/over fit. The model appears to perform well under both training sets</li>
        </ul>
        <li><strong>High Consistent Accuracy:</strong></li>
        <ul>
            <li>Both the training and cross validation scores around around 96.5% accuracy, which suggest that the model is performing well</li>
            <li>Because the scores are stable across different training set sizes, the model has reached a great level of performance</li>
        </ul>
        <li><strong>Gap Between Training and Validation:</strong></li>
        <ul>
            <li>The small gap between the scores suggest that the model does not deal with overfitting</li>
            <li>This is a good characteristic of a logistic regression model, as it indicates that the model is well suited to the data and is capturing the general patterns in both types of transactions</li>
        </ul>
        <li><strong>Shaded Areas:</strong></li>
        <ul>
            <li>The standard deviation between the training and validation is generally small, which means that the model's performance is consistent, indicating stability of the model.</li>
        </ul>
    </ul>
    <li><strong>ROC Curve</strong></li>
    <ul>
        <li>The ROS combined with the AUC, with a score of 0.99, gives us a full overview of the model's performance in distinguishing transactions.</li>
        <li><strong>Interpretation of the ROC Curve:</strong> The orange curve shows the model’s ability to distinguish between classes across different classification thresholds. The curve is close to the top left, which means that the true positive rate is high and the False positive rate is low.</li>
        <li><strong>AUC Score:</strong> A score of 0.99 suggests that the model has a high discriminatory power. This represents very close to ideal, which means that the model is effective in separating fraudulent and non fraudulent transactions.</li>
        <li><strong>Insights</strong></li>
        <ul>
            <li><strong>Strong performance:</strong> High performance can be derived from a high AUC score, which means that this model is well suited for fraud detection and can handle the imbalance nature</li>
            <li><strong>SMOTE Effectiveness:</strong> The use of SMOTE to balance the dataset contributes to the performance, as it ensures that the model is trained on a more balanced representation of both classes</li>
            <li><strong>Threshold Selection:</strong> The ROC curve indicates that the model achieves a high TP and low FP rate at multiple different thresholds.</li>
        </ul>
    </ul>
    <li><strong>Reasoning Behind Model Performance:</strong></li>
    <ul>
        <li><strong> Regression Suitability:</strong> Logistic regression is known for performing well on linearly separable data</li>
        <li><strong>Balanced Dataset with SMOTE:</strong> Addressing class imbalance allowed model to learn about patterns for fraud detection, which improved its ability to recognize transactions</li>
        <li><strong>Feature Scaling:</strong> Standardization of Amount feature and the selection of only informative features helped to reduce noise and focus</li>
    </ul>
</ul>


<h3>Next Steps</h3>
<ul>
    <li><strong>Fine Tune Decision:</strong> Depending on specific costs associated with FP and FN in the application</li>
    <li><strong>Experiment with Other Models:</strong> While this method performed well, trying to work with Gradient Boosting and Random Forests could improve performance by capturing any nonlinear relationships in the data.</li>
    <li><strong>Feature Engineering:</strong> Consider creating additional features based domain knowledge to enhance the model’s ability to detect subtle fraud patterns.</li>
    <li><strong>Regular Monitoring and Updating:</strong> Fraud patterns can change over time, so periodically retraining the model with recent data and monitoring performance in production will help with maintaining accuracy.</li>
</ul>


<h2>Gantt Chart</h2>
<p><a href="https://gtvault-my.sharepoint.com/:x:/g/personal/ssurapaneni36_gatech_edu/EbO8cFjxWttMmWSclcuOjIYBLSC7K3m4_zwGO0tdDGhxtQ">link to chart</a></p>

<h2>Contributions</h2>
<table border="1">
    <tr>
        <th>Contribution</th>
        <th>Names</th>
    </tr>
    <tr>
        <td><strong>Model 1 (M1) Design & Selection</strong></td>
        <td>Krithu</td>
    </tr>
    <tr>
        <td><strong>Implementing Algorithm</strong></td>
        <td>Krithu & Roland</td>
    </tr>
    <tr>
        <td><strong>Choosing Model and Research</strong></td>
        <td>Krithu & Winnie & Sanjana</td>
    </tr>
    <tr>
        <td><strong>Model Implementation</strong></td>
        <td>Nevin & Roland</td>
    </tr>
    <tr>
        <td><strong>Results & Discussion</strong></td>
        <td>All Members</td>
    </tr>
    <tr>
        <td><strong>GitHub Page</strong></td>
        <td>Sanjana & Winnie</td>
    </tr>
    <tr>
        <td><strong>GitHub Repo</strong></td>
        <td>Krithu & Roland</td>
    </tr>
</table>

<h2>Video and Recording</h2>
<p>The project proposal video and recording is here: <a href="https://www.youtube.com/watch?v=AMQi4BXrTsI">YouTube Unlisted Video</a></p>

<h2>GitHub</h2>
<p>You can access the project code and documentation via our GitHub repository: <a href="https://github.com/krith-raju/ML_CreditCard_Detection">ML_CreditCard_Detection</a></p>

<h2>References</h2>
<ol>
    <li>[1] Maniraj, S. P., Saini, A., Ahmed, S., & Sarkar, S. D. (2019). “Credit card fraud detection using machine learning and Data Science. Credit Card Fraud Detection Using Machine Learning and Data Science,” International Journal of Engineering Research & Technology., vol. 8, no. 9, pp. 110-115, 2019. [Online]. Available: https://doi.org/10.17577/ijertv8is090031</li>
    <li>[2] S. Safa and G. Ganga, "Credit Card Fraud Detection Using Logistic Regression," Master's Thesis, Rochester Institute of Technology, Rochester, NY, USA, 2020. [Online]. Available: https://repository.rit.edu/cgi/viewcontent.cgi?article=12455&context=theses</li>
    <li>[3] “Credit Card Fraud Detection Dataset 2023.” Kaggle. https://www.kaggle.com/datasets/nelgiriyewithana/credit-card-fraud-detection-dataset-2023 (accessed Oct. 24, 2024).</li>
    <li>[4] “Credit Card Fraud Detection Model.” Kaggle. Available: https://www.kaggle.com/models/evanschinonso/credit-card-fraud-detection (accessed Oct. 20, 2024).</li>
</ol>

</body>
</html>
